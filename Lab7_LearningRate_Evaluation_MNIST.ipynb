{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "1 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "2 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "3 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "4 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "5 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "6 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "7 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "8 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "9 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "10 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "11 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "12 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "13 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "14 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "15 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "16 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "17 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "18 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "19 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "20 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "21 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "22 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "23 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "24 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "25 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "26 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "27 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "28 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "29 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "30 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "31 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "32 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "33 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "34 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "35 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "36 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "37 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "38 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "39 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "40 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "41 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "42 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "43 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "44 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "45 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "46 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "47 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "48 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "49 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "50 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "51 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "52 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "53 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "54 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "55 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "56 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "57 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "58 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "59 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "60 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "61 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "62 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "63 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "64 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "65 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "66 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "67 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "68 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "69 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "70 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "71 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "72 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "73 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "74 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "75 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "76 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "77 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "78 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "79 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "80 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "81 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "82 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "83 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "84 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "85 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "86 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "87 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "88 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "89 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "90 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "91 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "92 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "93 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "94 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "95 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "96 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "97 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "98 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "99 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "100 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "101 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "102 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "103 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "104 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "105 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "106 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "107 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "108 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "109 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "110 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "111 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "112 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "113 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "114 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "115 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "116 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "117 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "118 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "119 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "120 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "121 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "122 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "123 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "124 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "125 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "126 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "127 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "128 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "129 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "130 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "131 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "132 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "133 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "134 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "135 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "136 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "137 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "138 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "139 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "140 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "141 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "142 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "143 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "144 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "145 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "146 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "147 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "148 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "149 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "150 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "151 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "152 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "153 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "154 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "155 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "156 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "157 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "158 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "159 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "160 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "161 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "162 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "163 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "164 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "165 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "166 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "167 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "168 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "169 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "170 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "171 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "172 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "174 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "175 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "176 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "177 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "178 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "179 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "180 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "181 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "182 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "183 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "184 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "185 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "186 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "187 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "188 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "189 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "190 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "191 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "192 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "193 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "194 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "195 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "196 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "197 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "198 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "199 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "200 6.50789 [[-0.65080774 -1.04305828  0.60942501]\n",
      " [ 0.47546631  0.35755107 -1.5768255 ]\n",
      " [ 0.70622247 -0.33584177 -1.81297767]]\n",
      "Prediction: [0 0 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "#Training Data\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "#Test Data\n",
    "\n",
    "#Training 데이터와 Test 데이터를 분리해야 한다.\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "#Placeholder를 이용하기 때문에 학습 데이터와 테스트 데이터를 feed_dict 따로 넣어주기만 하면 된다.\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "#tf.placeholder()는 입력 데이터를 만들 때 주로 사용한다. (실제 훈련 예제를 제공하는 변수) - 초기값을 지정할 필요 없다. (모델 입력시 변경되지 않을 데이터)\n",
    "#tf.Variable()은 데이터의 상태를 저장할 때 주로 사용한다. (가중치나 편향 등의 학습 가능한 변수) - 초기값을 지정해야 한다. (학습 되는 데이터)\n",
    "#http://stackoverflow.com/questions/36693740/whats-the-difference-between-tf-placeholder-and-tf-variable\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1)) #Cross entropy\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost) #최적화\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1) #arg_max : 가장 큰 값의 인덱스\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer()) #초기화\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "        #Training 데이터만으로 학습을 한다.\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))\n",
    "    #Test 데이터만으로 예측과 정확도 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate\n",
    "<img src=\"Images/lab7_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomalize\n",
    "\n",
    "<img src=\"Images/lab7_2.png\">\n",
    "\n",
    "<img src=\"Images/lab7_3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999999  0.99999999  0.          1.          1.        ]\n",
      " [ 0.70548491  0.70439552  1.          0.71881782  0.83755791]\n",
      " [ 0.54412549  0.50274824  0.57608696  0.606468    0.6606331 ]\n",
      " [ 0.33890353  0.31368023  0.10869565  0.45989134  0.43800918]\n",
      " [ 0.51436     0.42582389  0.30434783  0.58504805  0.42624401]\n",
      " [ 0.49556179  0.42582389  0.31521739  0.48131134  0.49276137]\n",
      " [ 0.11436064  0.          0.20652174  0.22007776  0.18597238]\n",
      " [ 0.          0.07747099  0.5326087   0.          0.        ]]\n",
      "0 Cost:  0.555502 \n",
      "Prediction:\n",
      " [[-0.1074009 ]\n",
      " [-0.24858361]\n",
      " [-0.21567595]\n",
      " [-0.19958508]\n",
      " [-0.17074841]\n",
      " [-0.10203714]\n",
      " [-0.167025  ]\n",
      " [-0.16953181]]\n",
      "1 Cost:  0.555461 \n",
      "Prediction:\n",
      " [[-0.10736327]\n",
      " [-0.24854736]\n",
      " [-0.21564589]\n",
      " [-0.19956191]\n",
      " [-0.17072086]\n",
      " [-0.10201059]\n",
      " [-0.16700752]\n",
      " [-0.16951475]]\n",
      "2 Cost:  0.555421 \n",
      "Prediction:\n",
      " [[-0.10732552]\n",
      " [-0.24851128]\n",
      " [-0.21561596]\n",
      " [-0.19953877]\n",
      " [-0.17069325]\n",
      " [-0.10198393]\n",
      " [-0.16699001]\n",
      " [-0.16949768]]\n",
      "3 Cost:  0.55538 \n",
      "Prediction:\n",
      " [[-0.10728776]\n",
      " [-0.24847507]\n",
      " [-0.21558583]\n",
      " [-0.19951558]\n",
      " [-0.17066562]\n",
      " [-0.10195732]\n",
      " [-0.16697255]\n",
      " [-0.16948062]]\n",
      "4 Cost:  0.555339 \n",
      "Prediction:\n",
      " [[-0.10725013]\n",
      " [-0.24843886]\n",
      " [-0.21555582]\n",
      " [-0.19949237]\n",
      " [-0.17063805]\n",
      " [-0.10193077]\n",
      " [-0.16695505]\n",
      " [-0.16946357]]\n",
      "5 Cost:  0.555298 \n",
      "Prediction:\n",
      " [[-0.1072125 ]\n",
      " [-0.24840267]\n",
      " [-0.21552576]\n",
      " [-0.19946922]\n",
      " [-0.1706105 ]\n",
      " [-0.10190417]\n",
      " [-0.16693757]\n",
      " [-0.1694465 ]]\n",
      "6 Cost:  0.555257 \n",
      "Prediction:\n",
      " [[-0.10717475]\n",
      " [-0.24836659]\n",
      " [-0.21549565]\n",
      " [-0.19944602]\n",
      " [-0.17058295]\n",
      " [-0.10187762]\n",
      " [-0.16692007]\n",
      " [-0.16942945]]\n",
      "7 Cost:  0.555216 \n",
      "Prediction:\n",
      " [[-0.10713699]\n",
      " [-0.24833038]\n",
      " [-0.21546558]\n",
      " [-0.19942287]\n",
      " [-0.17055532]\n",
      " [-0.10185096]\n",
      " [-0.1669026 ]\n",
      " [-0.16941239]]\n",
      "8 Cost:  0.555175 \n",
      "Prediction:\n",
      " [[-0.10709936]\n",
      " [-0.24829412]\n",
      " [-0.2154355 ]\n",
      " [-0.19939965]\n",
      " [-0.17052776]\n",
      " [-0.10182441]\n",
      " [-0.16688511]\n",
      " [-0.16939533]]\n",
      "9 Cost:  0.555134 \n",
      "Prediction:\n",
      " [[-0.10706173]\n",
      " [-0.24825798]\n",
      " [-0.21540539]\n",
      " [-0.19937651]\n",
      " [-0.1705002 ]\n",
      " [-0.1017978 ]\n",
      " [-0.16686761]\n",
      " [-0.16937827]]\n",
      "10 Cost:  0.555094 \n",
      "Prediction:\n",
      " [[-0.10702398]\n",
      " [-0.24822184]\n",
      " [-0.21537533]\n",
      " [-0.19935334]\n",
      " [-0.17047271]\n",
      " [-0.1017712 ]\n",
      " [-0.16685012]\n",
      " [-0.1693612 ]]\n",
      "11 Cost:  0.555053 \n",
      "Prediction:\n",
      " [[-0.10698622]\n",
      " [-0.24818569]\n",
      " [-0.21534532]\n",
      " [-0.19933012]\n",
      " [-0.17044508]\n",
      " [-0.10174465]\n",
      " [-0.16683266]\n",
      " [-0.16934416]]\n",
      "12 Cost:  0.555012 \n",
      "Prediction:\n",
      " [[-0.1069486 ]\n",
      " [-0.24814944]\n",
      " [-0.21531521]\n",
      " [-0.19930698]\n",
      " [-0.17041753]\n",
      " [-0.10171799]\n",
      " [-0.16681516]\n",
      " [-0.1693271 ]]\n",
      "13 Cost:  0.554971 \n",
      "Prediction:\n",
      " [[-0.10691097]\n",
      " [-0.2481133 ]\n",
      " [-0.21528515]\n",
      " [-0.19928381]\n",
      " [-0.17038998]\n",
      " [-0.10169145]\n",
      " [-0.16679768]\n",
      " [-0.16931005]]\n",
      "14 Cost:  0.55493 \n",
      "Prediction:\n",
      " [[-0.10687323]\n",
      " [-0.24807717]\n",
      " [-0.2152551 ]\n",
      " [-0.19926064]\n",
      " [-0.17036237]\n",
      " [-0.10166492]\n",
      " [-0.1667802 ]\n",
      " [-0.16929299]]\n",
      "15 Cost:  0.554889 \n",
      "Prediction:\n",
      " [[-0.10683548]\n",
      " [-0.24804103]\n",
      " [-0.21522498]\n",
      " [-0.19923747]\n",
      " [-0.17033482]\n",
      " [-0.10163826]\n",
      " [-0.16676274]\n",
      " [-0.16927594]]\n",
      "16 Cost:  0.554848 \n",
      "Prediction:\n",
      " [[-0.10679786]\n",
      " [-0.24800478]\n",
      " [-0.21519493]\n",
      " [-0.19921429]\n",
      " [-0.1703072 ]\n",
      " [-0.10161166]\n",
      " [-0.16674525]\n",
      " [-0.16925889]]\n",
      "17 Cost:  0.554808 \n",
      "Prediction:\n",
      " [[-0.10676023]\n",
      " [-0.24796864]\n",
      " [-0.21516487]\n",
      " [-0.19919112]\n",
      " [-0.17027965]\n",
      " [-0.10158506]\n",
      " [-0.16672777]\n",
      " [-0.16924183]]\n",
      "18 Cost:  0.554767 \n",
      "Prediction:\n",
      " [[-0.10672249]\n",
      " [-0.24793251]\n",
      " [-0.21513481]\n",
      " [-0.19916795]\n",
      " [-0.1702521 ]\n",
      " [-0.10155852]\n",
      " [-0.16671029]\n",
      " [-0.16922478]]\n",
      "19 Cost:  0.554726 \n",
      "Prediction:\n",
      " [[-0.10668474]\n",
      " [-0.24789625]\n",
      " [-0.21510476]\n",
      " [-0.19914481]\n",
      " [-0.17022449]\n",
      " [-0.10153192]\n",
      " [-0.16669279]\n",
      " [-0.16920772]]\n",
      "20 Cost:  0.554685 \n",
      "Prediction:\n",
      " [[-0.10664712]\n",
      " [-0.24786012]\n",
      " [-0.2150747 ]\n",
      " [-0.19912164]\n",
      " [-0.17019694]\n",
      " [-0.10150532]\n",
      " [-0.16667533]\n",
      " [-0.16919068]]\n",
      "21 Cost:  0.554644 \n",
      "Prediction:\n",
      " [[-0.10660949]\n",
      " [-0.24782404]\n",
      " [-0.21504459]\n",
      " [-0.19909847]\n",
      " [-0.17016938]\n",
      " [-0.10147879]\n",
      " [-0.16665785]\n",
      " [-0.16917363]]\n",
      "22 Cost:  0.554603 \n",
      "Prediction:\n",
      " [[-0.10657175]\n",
      " [-0.24778785]\n",
      " [-0.21501453]\n",
      " [-0.19907527]\n",
      " [-0.17014183]\n",
      " [-0.10145213]\n",
      " [-0.16664036]\n",
      " [-0.16915658]]\n",
      "23 Cost:  0.554563 \n",
      "Prediction:\n",
      " [[-0.106534  ]\n",
      " [-0.24775165]\n",
      " [-0.21498454]\n",
      " [-0.1990521 ]\n",
      " [-0.17011428]\n",
      " [-0.10142559]\n",
      " [-0.16662288]\n",
      " [-0.16913952]]\n",
      "24 Cost:  0.554522 \n",
      "Prediction:\n",
      " [[-0.10649638]\n",
      " [-0.24771546]\n",
      " [-0.21495442]\n",
      " [-0.19902892]\n",
      " [-0.17008673]\n",
      " [-0.10139899]\n",
      " [-0.16660541]\n",
      " [-0.16912247]]\n",
      "25 Cost:  0.554481 \n",
      "Prediction:\n",
      " [[-0.10645875]\n",
      " [-0.24767938]\n",
      " [-0.21492448]\n",
      " [-0.19900578]\n",
      " [-0.17005917]\n",
      " [-0.10137239]\n",
      " [-0.16658793]\n",
      " [-0.16910541]]\n",
      "26 Cost:  0.55444 \n",
      "Prediction:\n",
      " [[-0.10642102]\n",
      " [-0.24764326]\n",
      " [-0.21489444]\n",
      " [-0.1989826 ]\n",
      " [-0.17003164]\n",
      " [-0.10134586]\n",
      " [-0.16657045]\n",
      " [-0.16908836]]\n",
      "27 Cost:  0.554399 \n",
      "Prediction:\n",
      " [[-0.10638328]\n",
      " [-0.24760707]\n",
      " [-0.21486433]\n",
      " [-0.19895945]\n",
      " [-0.17000403]\n",
      " [-0.10131927]\n",
      " [-0.16655299]\n",
      " [-0.16907133]]\n",
      "28 Cost:  0.554358 \n",
      "Prediction:\n",
      " [[-0.10634566]\n",
      " [-0.24757093]\n",
      " [-0.21483427]\n",
      " [-0.19893625]\n",
      " [-0.16997647]\n",
      " [-0.10129268]\n",
      " [-0.16653553]\n",
      " [-0.1690543 ]]\n",
      "29 Cost:  0.554318 \n",
      "Prediction:\n",
      " [[-0.10630804]\n",
      " [-0.24753475]\n",
      " [-0.21480423]\n",
      " [-0.1989131 ]\n",
      " [-0.16994894]\n",
      " [-0.10126603]\n",
      " [-0.16651805]\n",
      " [-0.16903725]]\n",
      "30 Cost:  0.554277 \n",
      "Prediction:\n",
      " [[-0.10627031]\n",
      " [-0.24749863]\n",
      " [-0.21477413]\n",
      " [-0.19889   ]\n",
      " [-0.1699214 ]\n",
      " [-0.10123949]\n",
      " [-0.16650057]\n",
      " [-0.16902022]]\n",
      "31 Cost:  0.554236 \n",
      "Prediction:\n",
      " [[-0.10623257]\n",
      " [-0.2474625 ]\n",
      " [-0.21474414]\n",
      " [-0.1988668 ]\n",
      " [-0.16989379]\n",
      " [-0.10121296]\n",
      " [-0.1664831 ]\n",
      " [-0.16900319]]\n",
      "32 Cost:  0.554195 \n",
      "Prediction:\n",
      " [[-0.10619495]\n",
      " [-0.2474263 ]\n",
      " [-0.21471408]\n",
      " [-0.19884363]\n",
      " [-0.16986623]\n",
      " [-0.10118637]\n",
      " [-0.16646564]\n",
      " [-0.16898614]]\n",
      "33 Cost:  0.554155 \n",
      "Prediction:\n",
      " [[-0.10615733]\n",
      " [-0.24739018]\n",
      " [-0.21468398]\n",
      " [-0.19882047]\n",
      " [-0.1698387 ]\n",
      " [-0.10115978]\n",
      " [-0.16644818]\n",
      " [-0.16896911]]\n",
      "34 Cost:  0.554114 \n",
      "Prediction:\n",
      " [[-0.1061196 ]\n",
      " [-0.247354  ]\n",
      " [-0.214654  ]\n",
      " [-0.19879732]\n",
      " [-0.16981116]\n",
      " [-0.10113319]\n",
      " [-0.16643071]\n",
      " [-0.16895208]]\n",
      "35 Cost:  0.554073 \n",
      "Prediction:\n",
      " [[-0.10608186]\n",
      " [-0.24731793]\n",
      " [-0.21462394]\n",
      " [-0.19877411]\n",
      " [-0.16978355]\n",
      " [-0.1011066 ]\n",
      " [-0.16641323]\n",
      " [-0.16893503]]\n",
      "36 Cost:  0.554032 \n",
      "Prediction:\n",
      " [[-0.10604424]\n",
      " [-0.24728173]\n",
      " [-0.21459389]\n",
      " [-0.198751  ]\n",
      " [-0.16975605]\n",
      " [-0.10108007]\n",
      " [-0.16639575]\n",
      " [-0.168918  ]]\n",
      "37 Cost:  0.553991 \n",
      "Prediction:\n",
      " [[-0.10600662]\n",
      " [-0.24724561]\n",
      " [-0.21456385]\n",
      " [-0.19872782]\n",
      " [-0.16972852]\n",
      " [-0.10105342]\n",
      " [-0.16637829]\n",
      " [-0.16890097]]\n",
      "38 Cost:  0.553951 \n",
      "Prediction:\n",
      " [[-0.10596889]\n",
      " [-0.24720949]\n",
      " [-0.21453387]\n",
      " [-0.19870466]\n",
      " [-0.16970098]\n",
      " [-0.10102694]\n",
      " [-0.16636083]\n",
      " [-0.16888393]]\n",
      "39 Cost:  0.55391 \n",
      "Prediction:\n",
      " [[-0.10593127]\n",
      " [-0.24717343]\n",
      " [-0.21450382]\n",
      " [-0.19868153]\n",
      " [-0.16967344]\n",
      " [-0.10100036]\n",
      " [-0.16634336]\n",
      " [-0.1688669 ]]\n",
      "40 Cost:  0.553869 \n",
      "Prediction:\n",
      " [[-0.10589366]\n",
      " [-0.24713731]\n",
      " [-0.21447378]\n",
      " [-0.19865841]\n",
      " [-0.16964585]\n",
      " [-0.10097384]\n",
      " [-0.16632593]\n",
      " [-0.16884987]]\n",
      "41 Cost:  0.553828 \n",
      "Prediction:\n",
      " [[-0.10585605]\n",
      " [-0.24710125]\n",
      " [-0.21444386]\n",
      " [-0.19863525]\n",
      " [-0.16961837]\n",
      " [-0.10094731]\n",
      " [-0.16630846]\n",
      " [-0.16883284]]\n",
      "42 Cost:  0.553788 \n",
      "Prediction:\n",
      " [[-0.10581844]\n",
      " [-0.24706507]\n",
      " [-0.21441382]\n",
      " [-0.19861215]\n",
      " [-0.16959083]\n",
      " [-0.10092073]\n",
      " [-0.16629103]\n",
      " [-0.16881582]]\n",
      "43 Cost:  0.553747 \n",
      "Prediction:\n",
      " [[-0.10578083]\n",
      " [-0.24702901]\n",
      " [-0.21438378]\n",
      " [-0.19858906]\n",
      " [-0.16956335]\n",
      " [-0.10089426]\n",
      " [-0.16627358]\n",
      " [-0.16879877]]\n",
      "44 Cost:  0.553706 \n",
      "Prediction:\n",
      " [[-0.10574322]\n",
      " [-0.24699289]\n",
      " [-0.2143538 ]\n",
      " [-0.19856593]\n",
      " [-0.16953588]\n",
      " [-0.10086768]\n",
      " [-0.16625613]\n",
      " [-0.16878176]]\n",
      "45 Cost:  0.553666 \n",
      "Prediction:\n",
      " [[-0.10570561]\n",
      " [-0.24695688]\n",
      " [-0.21432382]\n",
      " [-0.19854277]\n",
      " [-0.16950834]\n",
      " [-0.10084116]\n",
      " [-0.1662387 ]\n",
      " [-0.16876473]]\n",
      "46 Cost:  0.553625 \n",
      "Prediction:\n",
      " [[-0.105668  ]\n",
      " [-0.24692076]\n",
      " [-0.21429378]\n",
      " [-0.19851968]\n",
      " [-0.1694808 ]\n",
      " [-0.10081463]\n",
      " [-0.16622123]\n",
      " [-0.16874769]]\n",
      "47 Cost:  0.553584 \n",
      "Prediction:\n",
      " [[-0.10563039]\n",
      " [-0.24688464]\n",
      " [-0.2142638 ]\n",
      " [-0.19849652]\n",
      " [-0.16945332]\n",
      " [-0.10078805]\n",
      " [-0.16620378]\n",
      " [-0.16873066]]\n",
      "48 Cost:  0.553543 \n",
      "Prediction:\n",
      " [[-0.10559278]\n",
      " [-0.24684852]\n",
      " [-0.21423388]\n",
      " [-0.19847345]\n",
      " [-0.16942579]\n",
      " [-0.10076153]\n",
      " [-0.16618633]\n",
      " [-0.16871363]]\n",
      "49 Cost:  0.553503 \n",
      "Prediction:\n",
      " [[-0.10555517]\n",
      " [-0.2468124 ]\n",
      " [-0.21420383]\n",
      " [-0.1984503 ]\n",
      " [-0.16939825]\n",
      " [-0.10073494]\n",
      " [-0.16616887]\n",
      " [-0.16869661]]\n",
      "50 Cost:  0.553462 \n",
      "Prediction:\n",
      " [[-0.10551756]\n",
      " [-0.2467764 ]\n",
      " [-0.21417379]\n",
      " [-0.19842717]\n",
      " [-0.16937083]\n",
      " [-0.10070848]\n",
      " [-0.16615143]\n",
      " [-0.16867957]]\n",
      "51 Cost:  0.553421 \n",
      "Prediction:\n",
      " [[-0.10547995]\n",
      " [-0.24674028]\n",
      " [-0.21414381]\n",
      " [-0.19840404]\n",
      " [-0.16934329]\n",
      " [-0.10068195]\n",
      " [-0.16613398]\n",
      " [-0.16866255]]\n",
      "52 Cost:  0.553381 \n",
      "Prediction:\n",
      " [[-0.10544234]\n",
      " [-0.24670416]\n",
      " [-0.21411383]\n",
      " [-0.19838092]\n",
      " [-0.16931576]\n",
      " [-0.10065543]\n",
      " [-0.16611655]\n",
      " [-0.16864553]]\n",
      "53 Cost:  0.55334 \n",
      "Prediction:\n",
      " [[-0.10540473]\n",
      " [-0.24666804]\n",
      " [-0.21408379]\n",
      " [-0.19835779]\n",
      " [-0.16928822]\n",
      " [-0.10062885]\n",
      " [-0.1660991 ]\n",
      " [-0.1686285 ]]\n",
      "54 Cost:  0.553299 \n",
      "Prediction:\n",
      " [[-0.10536713]\n",
      " [-0.24663204]\n",
      " [-0.21405381]\n",
      " [-0.19833466]\n",
      " [-0.16926068]\n",
      " [-0.10060228]\n",
      " [-0.16608167]\n",
      " [-0.16861147]]\n",
      "55 Cost:  0.553258 \n",
      "Prediction:\n",
      " [[-0.10532953]\n",
      " [-0.24659593]\n",
      " [-0.21402378]\n",
      " [-0.19831155]\n",
      " [-0.16923316]\n",
      " [-0.10057582]\n",
      " [-0.16606422]\n",
      " [-0.16859445]]\n",
      "56 Cost:  0.553218 \n",
      "Prediction:\n",
      " [[-0.10529193]\n",
      " [-0.24655989]\n",
      " [-0.21399388]\n",
      " [-0.19828841]\n",
      " [-0.16920575]\n",
      " [-0.10054924]\n",
      " [-0.16604677]\n",
      " [-0.16857743]]\n",
      "57 Cost:  0.553177 \n",
      "Prediction:\n",
      " [[-0.10525432]\n",
      " [-0.24652371]\n",
      " [-0.21396378]\n",
      " [-0.19826528]\n",
      " [-0.16917822]\n",
      " [-0.10052273]\n",
      " [-0.16602933]\n",
      " [-0.16856042]]\n",
      "58 Cost:  0.553136 \n",
      "Prediction:\n",
      " [[-0.10521672]\n",
      " [-0.24648765]\n",
      " [-0.2139338 ]\n",
      " [-0.19824216]\n",
      " [-0.16915074]\n",
      " [-0.10049621]\n",
      " [-0.1660119 ]\n",
      " [-0.1685434 ]]\n",
      "59 Cost:  0.553096 \n",
      "Prediction:\n",
      " [[-0.10517912]\n",
      " [-0.2464516 ]\n",
      " [-0.21390389]\n",
      " [-0.19821908]\n",
      " [-0.16912322]\n",
      " [-0.10046963]\n",
      " [-0.16599444]\n",
      " [-0.16852637]]\n",
      "60 Cost:  0.553055 \n",
      "Prediction:\n",
      " [[-0.10514151]\n",
      " [-0.2464155 ]\n",
      " [-0.21387386]\n",
      " [-0.19819593]\n",
      " [-0.1690957 ]\n",
      " [-0.10044312]\n",
      " [-0.165977  ]\n",
      " [-0.16850933]]\n",
      "61 Cost:  0.553014 \n",
      "Prediction:\n",
      " [[-0.10510391]\n",
      " [-0.24637938]\n",
      " [-0.21384388]\n",
      " [-0.19817287]\n",
      " [-0.16906822]\n",
      " [-0.10041654]\n",
      " [-0.16595957]\n",
      " [-0.16849232]]\n",
      "62 Cost:  0.552974 \n",
      "Prediction:\n",
      " [[-0.10506631]\n",
      " [-0.24634326]\n",
      " [-0.21381384]\n",
      " [-0.19814971]\n",
      " [-0.16904068]\n",
      " [-0.10039008]\n",
      " [-0.16594213]\n",
      " [-0.1684753 ]]\n",
      "63 Cost:  0.552933 \n",
      "Prediction:\n",
      " [[-0.1050287 ]\n",
      " [-0.24630727]\n",
      " [-0.21378393]\n",
      " [-0.1981266 ]\n",
      " [-0.16901322]\n",
      " [-0.10036357]\n",
      " [-0.16592468]\n",
      " [-0.16845828]]\n",
      "64 Cost:  0.552892 \n",
      "Prediction:\n",
      " [[-0.1049911 ]\n",
      " [-0.24627116]\n",
      " [-0.21375385]\n",
      " [-0.19810349]\n",
      " [-0.16898575]\n",
      " [-0.10033705]\n",
      " [-0.16590723]\n",
      " [-0.16844125]]\n",
      "65 Cost:  0.552852 \n",
      "Prediction:\n",
      " [[-0.1049535 ]\n",
      " [-0.2462351 ]\n",
      " [-0.21372387]\n",
      " [-0.19808039]\n",
      " [-0.16895822]\n",
      " [-0.10031053]\n",
      " [-0.1658898 ]\n",
      " [-0.16842423]]\n",
      "66 Cost:  0.552811 \n",
      "Prediction:\n",
      " [[-0.10491589]\n",
      " [-0.24619898]\n",
      " [-0.21369383]\n",
      " [-0.19805723]\n",
      " [-0.16893062]\n",
      " [-0.10028396]\n",
      " [-0.16587235]\n",
      " [-0.1684072 ]]\n",
      "67 Cost:  0.55277 \n",
      "Prediction:\n",
      " [[-0.1048783 ]\n",
      " [-0.24616289]\n",
      " [-0.21366388]\n",
      " [-0.19803417]\n",
      " [-0.16890317]\n",
      " [-0.10025745]\n",
      " [-0.16585492]\n",
      " [-0.16839018]]\n",
      "68 Cost:  0.55273 \n",
      "Prediction:\n",
      " [[-0.1048407 ]\n",
      " [-0.24612677]\n",
      " [-0.21363389]\n",
      " [-0.19801101]\n",
      " [-0.16887563]\n",
      " [-0.10023094]\n",
      " [-0.1658375 ]\n",
      " [-0.16837318]]\n",
      "69 Cost:  0.552689 \n",
      "Prediction:\n",
      " [[-0.10480311]\n",
      " [-0.2460908 ]\n",
      " [-0.21360388]\n",
      " [-0.19798791]\n",
      " [-0.16884819]\n",
      " [-0.10020437]\n",
      " [-0.16582006]\n",
      " [-0.16835618]]\n",
      "70 Cost:  0.552648 \n",
      "Prediction:\n",
      " [[-0.10476551]\n",
      " [-0.24605462]\n",
      " [-0.21357402]\n",
      " [-0.19796479]\n",
      " [-0.16882071]\n",
      " [-0.10017786]\n",
      " [-0.16580263]\n",
      " [-0.16833916]]\n",
      "71 Cost:  0.552608 \n",
      "Prediction:\n",
      " [[-0.10472792]\n",
      " [-0.24601865]\n",
      " [-0.21354401]\n",
      " [-0.19794172]\n",
      " [-0.1687932 ]\n",
      " [-0.10015129]\n",
      " [-0.16578519]\n",
      " [-0.16832215]]\n",
      "72 Cost:  0.552567 \n",
      "Prediction:\n",
      " [[-0.10469032]\n",
      " [-0.24598247]\n",
      " [-0.21351397]\n",
      " [-0.19791856]\n",
      " [-0.16876566]\n",
      " [-0.10012484]\n",
      " [-0.16576776]\n",
      " [-0.16830513]]\n",
      "73 Cost:  0.552526 \n",
      "Prediction:\n",
      " [[-0.10465273]\n",
      " [-0.2459465 ]\n",
      " [-0.21348396]\n",
      " [-0.19789544]\n",
      " [-0.16873822]\n",
      " [-0.10009827]\n",
      " [-0.16575032]\n",
      " [-0.16828811]]\n",
      "74 Cost:  0.552486 \n",
      "Prediction:\n",
      " [[-0.10461513]\n",
      " [-0.24591044]\n",
      " [-0.21345398]\n",
      " [-0.19787234]\n",
      " [-0.16871068]\n",
      " [-0.10007171]\n",
      " [-0.16573289]\n",
      " [-0.16827109]]\n",
      "75 Cost:  0.552445 \n",
      "Prediction:\n",
      " [[-0.10457753]\n",
      " [-0.24587429]\n",
      " [-0.21342403]\n",
      " [-0.19784921]\n",
      " [-0.16868317]\n",
      " [-0.10004526]\n",
      " [-0.16571546]\n",
      " [-0.16825408]]\n",
      "76 Cost:  0.552404 \n",
      "Prediction:\n",
      " [[-0.10453994]\n",
      " [-0.24583817]\n",
      " [-0.21339405]\n",
      " [-0.19782615]\n",
      " [-0.16865575]\n",
      " [-0.10001875]\n",
      " [-0.16569801]\n",
      " [-0.16823706]]\n",
      "77 Cost:  0.552364 \n",
      "Prediction:\n",
      " [[-0.10450234]\n",
      " [-0.24580207]\n",
      " [-0.21336409]\n",
      " [-0.19780302]\n",
      " [-0.16862819]\n",
      " [-0.09999218]\n",
      " [-0.16568057]\n",
      " [-0.16822004]]\n",
      "78 Cost:  0.552323 \n",
      "Prediction:\n",
      " [[-0.10446475]\n",
      " [-0.24576601]\n",
      " [-0.21333405]\n",
      " [-0.19777989]\n",
      " [-0.16860065]\n",
      " [-0.09996573]\n",
      " [-0.16566315]\n",
      " [-0.16820303]]\n",
      "79 Cost:  0.552283 \n",
      "Prediction:\n",
      " [[-0.10442715]\n",
      " [-0.24572998]\n",
      " [-0.21330404]\n",
      " [-0.19775683]\n",
      " [-0.1685732 ]\n",
      " [-0.09993916]\n",
      " [-0.16564572]\n",
      " [-0.16818601]]\n",
      "80 Cost:  0.552242 \n",
      "Prediction:\n",
      " [[-0.10438956]\n",
      " [-0.24569392]\n",
      " [-0.213274  ]\n",
      " [-0.1977337 ]\n",
      " [-0.16854566]\n",
      " [-0.09991265]\n",
      " [-0.16562828]\n",
      " [-0.16816901]]\n",
      "81 Cost:  0.552201 \n",
      "Prediction:\n",
      " [[-0.10435197]\n",
      " [-0.24565777]\n",
      " [-0.21324411]\n",
      " [-0.19771057]\n",
      " [-0.16851816]\n",
      " [-0.09988609]\n",
      " [-0.16561085]\n",
      " [-0.168152  ]]\n",
      "82 Cost:  0.552161 \n",
      "Prediction:\n",
      " [[-0.10431438]\n",
      " [-0.2456218 ]\n",
      " [-0.21321416]\n",
      " [-0.19768751]\n",
      " [-0.16849071]\n",
      " [-0.09985959]\n",
      " [-0.16559345]\n",
      " [-0.16813499]]\n",
      "83 Cost:  0.55212 \n",
      "Prediction:\n",
      " [[-0.10427679]\n",
      " [-0.24558569]\n",
      " [-0.21318419]\n",
      " [-0.19766439]\n",
      " [-0.16846325]\n",
      " [-0.09983309]\n",
      " [-0.165576  ]\n",
      " [-0.168118  ]]\n",
      "84 Cost:  0.552079 \n",
      "Prediction:\n",
      " [[-0.1042392 ]\n",
      " [-0.24554965]\n",
      " [-0.21315411]\n",
      " [-0.19764128]\n",
      " [-0.16843572]\n",
      " [-0.09980652]\n",
      " [-0.16555858]\n",
      " [-0.16810098]]\n",
      "85 Cost:  0.552039 \n",
      "Prediction:\n",
      " [[-0.10420161]\n",
      " [-0.2455135 ]\n",
      " [-0.21312422]\n",
      " [-0.19761816]\n",
      " [-0.16840827]\n",
      " [-0.09978002]\n",
      " [-0.16554114]\n",
      " [-0.16808397]]\n",
      "86 Cost:  0.551998 \n",
      "Prediction:\n",
      " [[-0.10416403]\n",
      " [-0.24547747]\n",
      " [-0.2130942 ]\n",
      " [-0.19759509]\n",
      " [-0.16838077]\n",
      " [-0.09975346]\n",
      " [-0.16552372]\n",
      " [-0.16806698]]\n",
      "87 Cost:  0.551957 \n",
      "Prediction:\n",
      " [[-0.10412644]\n",
      " [-0.24544142]\n",
      " [-0.21306418]\n",
      " [-0.19757195]\n",
      " [-0.16835324]\n",
      " [-0.09972702]\n",
      " [-0.1655063 ]\n",
      " [-0.16804996]]\n",
      "88 Cost:  0.551917 \n",
      "Prediction:\n",
      " [[-0.10408885]\n",
      " [-0.24540538]\n",
      " [-0.21303427]\n",
      " [-0.1975489 ]\n",
      " [-0.16832578]\n",
      " [-0.09970058]\n",
      " [-0.16548887]\n",
      " [-0.16803294]]\n",
      "89 Cost:  0.551876 \n",
      "Prediction:\n",
      " [[-0.10405126]\n",
      " [-0.24536929]\n",
      " [-0.21300426]\n",
      " [-0.19752577]\n",
      " [-0.16829833]\n",
      " [-0.09967402]\n",
      " [-0.16547145]\n",
      " [-0.16801594]]\n",
      "90 Cost:  0.551836 \n",
      "Prediction:\n",
      " [[-0.10401367]\n",
      " [-0.24533314]\n",
      " [-0.21297431]\n",
      " [-0.19750267]\n",
      " [-0.16827083]\n",
      " [-0.09964751]\n",
      " [-0.16545402]\n",
      " [-0.16799894]]\n",
      "91 Cost:  0.551795 \n",
      "Prediction:\n",
      " [[-0.10397609]\n",
      " [-0.24529709]\n",
      " [-0.21294428]\n",
      " [-0.19747956]\n",
      " [-0.1682433 ]\n",
      " [-0.09962095]\n",
      " [-0.1654366 ]\n",
      " [-0.16798192]]\n",
      "92 Cost:  0.551754 \n",
      "Prediction:\n",
      " [[-0.1039385 ]\n",
      " [-0.24526098]\n",
      " [-0.21291432]\n",
      " [-0.19745642]\n",
      " [-0.16821578]\n",
      " [-0.09959445]\n",
      " [-0.16541916]\n",
      " [-0.16796492]]\n",
      "93 Cost:  0.551714 \n",
      "Prediction:\n",
      " [[-0.10390091]\n",
      " [-0.24522501]\n",
      " [-0.21288437]\n",
      " [-0.19743332]\n",
      " [-0.16818827]\n",
      " [-0.09956789]\n",
      " [-0.16540173]\n",
      " [-0.16794792]]\n",
      "94 Cost:  0.551673 \n",
      "Prediction:\n",
      " [[-0.10386332]\n",
      " [-0.24518892]\n",
      " [-0.21285436]\n",
      " [-0.19741026]\n",
      " [-0.16816083]\n",
      " [-0.09954139]\n",
      " [-0.16538429]\n",
      " [-0.1679309 ]]\n",
      "95 Cost:  0.551633 \n",
      "Prediction:\n",
      " [[-0.10382574]\n",
      " [-0.24515289]\n",
      " [-0.2128244 ]\n",
      " [-0.19738716]\n",
      " [-0.16813338]\n",
      " [-0.09951495]\n",
      " [-0.1653669 ]\n",
      " [-0.16791391]]\n",
      "96 Cost:  0.551592 \n",
      "Prediction:\n",
      " [[-0.10378816]\n",
      " [-0.24511674]\n",
      " [-0.21279445]\n",
      " [-0.19736403]\n",
      " [-0.16810587]\n",
      " [-0.0994884 ]\n",
      " [-0.16534947]\n",
      " [-0.1678969 ]]\n",
      "97 Cost:  0.551551 \n",
      "Prediction:\n",
      " [[-0.10375058]\n",
      " [-0.24508083]\n",
      " [-0.2127645 ]\n",
      " [-0.19734097]\n",
      " [-0.16807842]\n",
      " [-0.09946185]\n",
      " [-0.16533205]\n",
      " [-0.16787992]]\n",
      "98 Cost:  0.551511 \n",
      "Prediction:\n",
      " [[-0.103713  ]\n",
      " [-0.24504474]\n",
      " [-0.21273449]\n",
      " [-0.19731787]\n",
      " [-0.16805092]\n",
      " [-0.09943541]\n",
      " [-0.16531464]\n",
      " [-0.16786292]]\n",
      "99 Cost:  0.55147 \n",
      "Prediction:\n",
      " [[-0.10367542]\n",
      " [-0.24500871]\n",
      " [-0.21270454]\n",
      " [-0.1972948 ]\n",
      " [-0.16802341]\n",
      " [-0.09940892]\n",
      " [-0.16529724]\n",
      " [-0.16784593]]\n",
      "100 Cost:  0.55143 \n",
      "Prediction:\n",
      " [[-0.10363784]\n",
      " [-0.24497256]\n",
      " [-0.21267459]\n",
      " [-0.19727167]\n",
      " [-0.16799596]\n",
      " [-0.09938242]\n",
      " [-0.16527981]\n",
      " [-0.16782895]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0) #데이터 - 최소값. np.min(data, 0) : data의 최소값, 0차원에 대해. 열에 대한 최소값이 구해진다.\n",
    "    denominator = np.max(data, 0) - np.min(data, 0) #최대값 - 최소값\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7) #0으로 나눠지는 것을 막기 위해 작은 값을 더한다.\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "#데이터가 크거나 들쑥날쑥한 경우에는 정규화를 해줘야 한다.\n",
    "\n",
    "# very important. It does not work without it.\n",
    "xy = MinMaxScaler(xy)\n",
    "print(xy)\n",
    "#정규화하지 않고 진행할 경우 값이 발산해서 Nan이 나온다.\n",
    "\n",
    "x_data = xy[:, 0:-1] #전체 행을 가져온다, 각 행의 0 ~ index-1 행까지 가져온다.\n",
    "y_data = xy[:, [-1]] #전체 행을 가져온다, 각 행의 마지막 행만 가져온다.\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4]) #전체 요소의 개수는 n, 각 요소는 4개씩\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1]) #전체 요소의 개수는 n, 각 요소는 1개씩\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "#tf.placeholder()는 입력 데이터를 만들 때 주로 사용한다. (실제 훈련 예제를 제공하는 변수) - 초기값을 지정할 필요 없다. (모델 입력시 변경되지 않을 데이터)\n",
    "#tf.Variable()은 데이터의 상태를 저장할 때 주로 사용한다. (가중치나 편향 등의 학습 가능한 변수) - 초기값을 지정해야 한다. (학습 되는 데이터)\n",
    "#http://stackoverflow.com/questions/36693740/whats-the-difference-between-tf-placeholder-and-tf-variable\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) #평균 제곱 오차\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost) #최적화\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer()) #초기화\n",
    "    \n",
    "    for step in range(101):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
