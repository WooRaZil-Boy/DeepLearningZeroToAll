{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/lab5_1.png\">\n",
    "<img src=\"Images/lab5_2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import readchar\n",
    "\n",
    "# MACROS\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "# Key mapping\n",
    "arrow_keys = {\n",
    "    '\\x1b[A': UP,\n",
    "    '\\x1b[B': DOWN,\n",
    "    '\\x1b[C': RIGHT,\n",
    "    '\\x1b[D': LEFT}\n",
    "\n",
    "# is_slippery True\n",
    "env = gym.make('FrozenLake-v0') #'is_slippery': True로 설정된 게임 환경\n",
    "env.reset()\n",
    "\n",
    "env.render()  # Show the initial board\n",
    "\n",
    "while True:\n",
    "    # Choose an action from keyboard\n",
    "    key = readchar.readkey()\n",
    "    if key not in arrow_keys.keys():\n",
    "        print(\"Game aborted!\")\n",
    "        break\n",
    "\n",
    "    action = arrow_keys[key]\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()  # Show the board after action\n",
    "    print(\"State: \", state, \"Action: \", action,\n",
    "          \"Reward: \", reward, \"Info: \", info)\n",
    "\n",
    "    if done:\n",
    "        print(\"Finished with reward\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nondeterministic Worlds\n",
    "\n",
    "이전과 동일한 Q-learning 알고리즘에 Nondeterministic Worlds 환경만 추가해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-01 16:04:13,565] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "# Set learning parameters\n",
    "learning_rate = .85\n",
    "dis = .99\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-01 15:51:13,523] Making new env: FrozenLake-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.0175\n",
      "Final Q-Table Values\n",
      "[[ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.9801  0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.    ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADyRJREFUeJzt3X+s3Xddx/Hny5YR5deAXslsO9slBW2i4LjO/QGIQaFd\nlIoa00EcTJJmyUYgxkgNCZLwFxqMIQyais3AKCWGIdUUhxiFP3CyW1K2ldFxKT/WMrYODKgYZ93b\nP863cHrovfd7bs89p/fD85Hc7JzP93PP99XPOX31e7/nnu9SVUiS2vIjsw4gSZo8y12SGmS5S1KD\nLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUoI2z2vGmTZtq27Zts9q9JK1Lx44de6yq5laaN7Ny\n37ZtGwsLC7PavSStS0m+2meep2UkqUGWuyQ1yHKXpAZZ7pLUIMtdkhq0YrknOZTk0ST3L7E9Sd6V\nZDHJvUmunXxMSdI4+hy53wHsWmb7bmBH97UPeO+lx5IkXYoVy72qPgV8a5kpe4AP1MDdwJVJrppU\nQEnS+CZxzn0z8NDQ/dPdmCRpRqb6hmqSfUkWkiycPXt2mrsWkMw6QX/rKet5o5kn9WdYj2uh2ZtE\nuZ8Btg7d39KN/YCqOlhV81U1Pze34qURJEmrNIlyPwLc1P3WzPXAt6vq4Qk8riRplVa8cFiSDwIv\nBTYlOQ38EfAkgKo6ABwFbgAWge8CN69VWElSPyuWe1XduML2Am6dWCJJ0iXzE6qS1CDLXZIaZLlL\nUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1\nyHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMs\nd0lqkOUuSQ2y3CWpQZa7JDXIcpekBvUq9yS7kpxMsphk/0W2PyPJ3yX5XJITSW6efFRJUl8rlnuS\nDcDtwG5gJ3Bjkp0j024FPl9VzwdeCrwzyRUTzipJ6qnPkft1wGJVnaqqx4HDwJ6ROQU8LUmApwLf\nAs5NNKkkqbc+5b4ZeGjo/ulubNi7gZ8Gvg7cB7yxqp6YSEJJ0tgm9YbqK4DjwE8ALwDeneTpo5OS\n7EuykGTh7NmzE9q1JGlUn3I/A2wdur+lGxt2M3BnDSwCXwZ+avSBqupgVc1X1fzc3NxqM0uSVtCn\n3O8BdiTZ3r1Juhc4MjLna8DLAJI8B3gecGqSQSVJ/W1caUJVnUtyG3AXsAE4VFUnktzSbT8AvB24\nI8l9QIA3V9Vja5hbkrSMFcsdoKqOAkdHxg4M3f468PLJRpMkrZafUJWkBlnuktQgy12SGmS5S1KD\nLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchy\nl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJ\napDlLkkNstwlqUGWuyQ1yHKXpAb1Kvcku5KcTLKYZP8Sc16a5HiSE0k+OdmYkqRxbFxpQpINwO3A\nrwCngXuSHKmqzw/NuRJ4D7Crqr6W5MfXKrAkaWV9jtyvAxar6lRVPQ4cBvaMzHk1cGdVfQ2gqh6d\nbExJ0jj6lPtm4KGh+6e7sWHPBZ6Z5F+SHEty06QCSpLGt+JpmTEe54XAy4AfBf41yd1V9eDwpCT7\ngH0AV1999YR2LUka1efI/Qywdej+lm5s2Gngrqr6r6p6DPgU8PzRB6qqg1U1X1Xzc3Nzq80sSVpB\nn3K/B9iRZHuSK4C9wJGROR8FXpRkY5IfA34BeGCyUSVJfa14WqaqziW5DbgL2AAcqqoTSW7pth+o\nqgeS/ANwL/AE8L6qun8tg0uSlpaqmsmO5+fna2FhYSb7/mGVwIye7rGtp6znjWae1J9hPa6F1k6S\nY1U1v9I8P6EqSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1\nyHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMs\nd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJalCvck+yK8nJJItJ9i8z7+eT\nnEvyW5OLKEka14rlnmQDcDuwG9gJ3Jhk5xLz3gF8fNIhJUnj6XPkfh2wWFWnqupx4DCw5yLz3gB8\nGHh0gvkkSavQp9w3Aw8N3T/djX1Pks3Aq4D3Ti6aJGm1JvWG6p8Bb66qJ5ablGRfkoUkC2fPnp3Q\nriVJozb2mHMG2Dp0f0s3NmweOJwEYBNwQ5JzVfW3w5Oq6iBwEGB+fr5WG1qStLw+5X4PsCPJdgal\nvhd49fCEqtp+/naSO4C/Hy12SdL0rFjuVXUuyW3AXcAG4FBVnUhyS7f9wBpnlCSNqc+RO1V1FDg6\nMnbRUq+q1116LEnSpfATqpLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDL\nXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwl\nqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1KBe5Z5k\nV5KTSRaT7L/I9tckuTfJfUk+neT5k48qSeprxXJPsgG4HdgN7ARuTLJzZNqXgV+sqp8B3g4cnHRQ\nSVJ/fY7crwMWq+pUVT0OHAb2DE+oqk9X1b93d+8Gtkw2piRpHH3KfTPw0ND9093YUl4PfOxiG5Ls\nS7KQZOHs2bP9U0qSxjLRN1ST/BKDcn/zxbZX1cGqmq+q+bm5uUnuWpI0ZGOPOWeArUP3t3RjF0jy\ns8D7gN1V9c3JxJMkrUafI/d7gB1Jtie5AtgLHBmekORq4E7gd6rqwcnHlCSNY8Uj96o6l+Q24C5g\nA3Coqk4kuaXbfgB4K/Bs4D1JAM5V1fzaxZYkLSdVNZMdz8/P18LCwkz2/cMqgRk93WNbT1nPG808\nqT/DelwLrZ0kx/ocPPsJVUlqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDl\nLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S\n1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDepV7kl1JTiZZ\nTLL/ItuT5F3d9nuTXDv5qJKkvlYs9yQbgNuB3cBO4MYkO0em7QZ2dF/7gPdOOKckaQx9jtyvAxar\n6lRVPQ4cBvaMzNkDfKAG7gauTHLVhLNKknrqU+6bgYeG7p/uxsadI0mako3T3FmSfQxO2wD8Z5KT\nq3yoTcBjk0k1cZdrtk3AY8msY/yAJddrxllX9TyOZp7Un2HocS7r19esQ1xEi7l+ss+kPuV+Btg6\ndH9LNzbuHKrqIHCwT7DlJFmoqvlLfZy1cLlmM9d4zDUec41nGrn6nJa5B9iRZHuSK4C9wJGROUeA\nm7rfmrke+HZVPTzhrJKknlY8cq+qc0luA+4CNgCHqupEklu67QeAo8ANwCLwXeDmtYssSVpJr3Pu\nVXWUQYEPjx0Yul3ArZONtqxLPrWzhi7XbOYaj7nGY67xrHmuDHpZktQSLz8gSQ1ad+W+0qUQ1njf\nW5P8c5LPJzmR5I3d+NuSnElyvPu6Yeh7/rDLejLJK9Yw21eS3Nftf6Ebe1aSf0zyxe6/z5xmriTP\nG1qT40m+k+RNs1ivJIeSPJrk/qGxsdcnyQu7dV7sLrlxSb/suESuP0nyhe5SHh9JcmU3vi3Jfw+t\n24Gh75lGrrGftynl+tBQpq8kOd6NT3O9luqG2b3GqmrdfDF4Q/dLwDXAFcDngJ1T3P9VwLXd7acB\nDzK4JMPbgN+/yPydXcYnA9u77BvWKNtXgE0jY38M7O9u7wfeMe1cI8/dNxj8ju7U1wt4CXAtcP+l\nrA/wGeB6IMDHgN1rkOvlwMbu9juGcm0bnjfyONPINfbzNo1cI9vfCbx1Buu1VDfM7DW23o7c+1wK\nYc1U1cNV9dnu9n8AD7D8J3H3AIer6n+q6ssMfpvourVPesH+39/dfj/w6zPM9TLgS1X11WXmrFmu\nqvoU8K2L7K/3+mRwSY2nV9XdNfhb+IGh75lYrqr6eFWd6+7ezeBzI0uaVq5lzHS9zuuOcH8b+OBy\nj7FGuZbqhpm9xtZbuV82lzlIsg34OeDfuqE3dD9GHxr60WuaeQv4RJJjGXwSGOA59f3PG3wDeM4M\ncp23lwv/0s16vWD89dnc3Z5WPoDfZXD0dt727hTDJ5O8uBubZq5xnrdpr9eLgUeq6otDY1Nfr5Fu\nmNlrbL2V+2UhyVOBDwNvqqrvMLgK5jXAC4CHGfxoOG0vqqoXMLhC561JXjK8sTsKmMmvRmXw4bdX\nAn/TDV0O63WBWa7PUpK8BTgH/FU39DBwdfc8/x7w10mePsVIl93zNuJGLjyAmPp6XaQbvmfar7H1\nVu69LnOwlpI8icGT91dVdSdAVT1SVf9XVU8Af873TyVMLW9Vnen++yjwkS7DI92Peed/FH102rk6\nu4HPVtUjXcaZr1dn3PU5w4WnSNYsX5LXAb8KvKYrBbof4b/Z3T7G4Dztc6eVaxXP2zTXayPwG8CH\nhvJOdb0u1g3M8DW23sq9z6UQ1kx3Tu8vgAeq6k+Hxocvb/wq4Pw7+UeAvUmenGQ7g+vdf2YNcj0l\nydPO32bwhtz93f5f2017LfDRaeYacsER1azXa8hY69P9eP2dJNd3r4Wbhr5nYpLsAv4AeGVVfXdo\nfC6D/78CSa7pcp2aYq6xnrdp5er8MvCFqvreKY1prtdS3cAsX2OX8g7xLL4YXObgQQb/Cr9lyvt+\nEYMfq+4FjndfNwB/CdzXjR8Brhr6nrd0WU9yie/IL5PrGgbvvH8OOHF+XYBnA/8EfBH4BPCsaebq\n9vMU4JvAM4bGpr5eDP5xeRj4XwbnMV+/mvUB5hmU2peAd9N9EHDCuRYZnI89/xo70M39ze75PQ58\nFvi1Keca+3mbRq5u/A7glpG501yvpbphZq8xP6EqSQ1ab6dlJEk9WO6S1CDLXZIaZLlLUoMsd0lq\nkOUuSQ2y3CWpQZa7JDXo/wHht+SMv+JsQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1161c1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    # Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "\n",
    "    # The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        # Choose an action by greedily (with noise) picking from Q table\n",
    "        action = np.argmax(Q[state, :] + np.random.randn(1, env.action_space.n) / (i + 1))\n",
    "\n",
    "        # Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update Q-Table with new knowledge using learning rate\n",
    "        Q[state, action] = reward + dis * np.max(Q[new_state, :])\n",
    "        state = new_state\n",
    "\n",
    "        rAll += reward\n",
    "\n",
    "    rList.append(rAll)\n",
    "\n",
    "print(\"Score over time: \" + str(sum(rList) / num_episodes))\n",
    "print(\"Final Q-Table Values\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "plt.show()\n",
    "\n",
    "#학습이 잘 되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nondeterministic Worlds with learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/lab5_3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.5015\n",
      "Final Q-Table Values\n",
      "[[  1.21776483e-02   1.11345101e-02   4.42153359e-01   1.94973347e-02]\n",
      " [  8.61446764e-04   8.71945507e-03   4.21875032e-03   2.75375578e-01]\n",
      " [  7.68012124e-03   9.15655635e-03   9.82316686e-03   2.01261715e-01]\n",
      " [  6.38150931e-03   1.14480012e-03   0.00000000e+00   1.75910724e-01]\n",
      " [  5.75791714e-01   4.01898158e-04   2.06156817e-04   4.73988868e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.38920544e-05   2.39606010e-07   1.79608829e-04   3.76367623e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.06724269e-03   0.00000000e+00   9.37811241e-04   8.27673295e-01]\n",
      " [  4.23431385e-04   9.24485440e-01   1.85529797e-03   3.88498690e-04]\n",
      " [  1.61103425e-01   3.96439696e-04   1.18613879e-04   3.12884164e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.34277239e-02   0.00000000e+00   9.27332631e-01   3.10203238e-02]\n",
      " [  0.00000000e+00   9.72181478e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqQ5S5JDbLcJalBlrskNej/AUuZ07zp9vXPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e1d0550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    # Reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "\n",
    "    # The Q-Table learning algorithm\n",
    "    while not done:\n",
    "        # Choose an action by greedily (with noise) picking from Q table\n",
    "        action = np.argmax(Q[state, :] + np.random.randn(1, env.action_space.n) / (i + 1))\n",
    "\n",
    "        # Get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update Q-Table with new knowledge using learning rate\n",
    "        Q[state, action] = (1 - learning_rate) * Q[state, action] + learning_rate * (reward + dis * np.max(Q[new_state, :]))\n",
    "        #이 부분만 수정\n",
    "        state = new_state\n",
    "\n",
    "        rAll += reward\n",
    "\n",
    "    rList.append(rAll)\n",
    "\n",
    "print(\"Score over time: \" + str(sum(rList) / num_episodes))\n",
    "print(\"Final Q-Table Values\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
